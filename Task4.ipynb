{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63caa08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\khush\\anaconda3\\lib\\site-packages (1.2.4)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\khush\\anaconda3\\lib\\site-packages (1.20.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\khush\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from scikit-learn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\khush\\anaconda3\\lib\\site-packages (from scikit-learn) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9dab6d",
   "metadata": {},
   "source": [
    "In this code, we have loaded the dataset \"spam.csv\" from Kaggle, split it into training and testing sets, converted the text data into numerical features using CountVectorizer, and trained the Naive Bayes classifier on the training data. Finally, we evaluated the performance of the model on the testing data and printed accuracy, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d57370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9838565022421525\n",
      "Confusion Matrix:\n",
      "[[963   2]\n",
      " [ 16 134]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       965\n",
      "        spam       0.99      0.89      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Load the dataset (Make sure \"spam.csv\" is in the same directory)\n",
    "data = pd.read_csv(\"spam.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Drop unnecessary columns and rename columns\n",
    "data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "data.columns = [\"label\", \"text\"]\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], data[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Feature Extraction\n",
    "# Convert text data into numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 4: Building the Spam Detector (Naive Bayes Classifier)\n",
    "spam_detector = MultinomialNB()\n",
    "spam_detector.fit(X_train_counts, y_train)\n",
    "\n",
    "# Step 5: Evaluating the Model\n",
    "y_pred = spam_detector.predict(X_test_counts)\n",
    "\n",
    "# Calculate accuracy and other metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14c88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
